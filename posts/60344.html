<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Shortcut Learning in Deep Neural Networks | Minghao's Page</title><meta name="author" content="Minghao Wang"><meta name="copyright" content="Minghao Wang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Shortcut Learning – 捷径学习 What is a shortcut?  shortcuts are decision rules that perform well on i.i.d. test data but fail on o.o.d. tests, revealing a mismatch between intended and learned solution.">
<meta property="og:type" content="article">
<meta property="og:title" content="Shortcut Learning in Deep Neural Networks">
<meta property="og:url" content="http://apple1203.github.io/posts/60344.html">
<meta property="og:site_name" content="Minghao&#39;s Page">
<meta property="og:description" content="Shortcut Learning – 捷径学习 What is a shortcut?  shortcuts are decision rules that perform well on i.i.d. test data but fail on o.o.d. tests, revealing a mismatch between intended and learned solution.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://apple1203.github.io/medias/PostPics/16.jpg">
<meta property="article:published_time" content="2022-08-01T04:30:00.000Z">
<meta property="article:modified_time" content="2022-10-06T19:42:37.837Z">
<meta property="article:author" content="Minghao Wang">
<meta property="article:tag" content="Medical AI">
<meta property="article:tag" content="Paper Sharing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://apple1203.github.io/medias/PostPics/16.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://apple1203.github.io/posts/60344"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Shortcut Learning in Deep Neural Networks',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-10-07 03:42:37'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/minghao.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/medias/PostPics/16.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Minghao's Page</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Shortcut Learning in Deep Neural Networks</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-01T04:30:00.000Z" title="发表于 2022-08-01 12:30:00">2022-08-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-10-06T19:42:37.837Z" title="更新于 2022-10-07 03:42:37">2022-10-07</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>11分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Shortcut Learning in Deep Neural Networks"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>Shortcut Learning – 捷径学习</h1>
<p><font size = "4"><em><strong>What is a shortcut?</strong></em></font></p>
<blockquote>
<p>shortcuts are decision rules that perform well on i.i.d. test data but fail on o.o.d. tests, revealing a mismatch between intended and learned solution.</p>
</blockquote>
<p>本文主要分享的是实验室中的深度学习应用到现实中不适配的问题。</p>
<h2 id="1-Introduction">1. Introduction</h2>
<p>深度学习在对我们的生产生活起到很大帮助的同时，人们必须意识到一个问题，如果想将其应用到自动驾驶、简历评估、癌症筛查（<strong>共同特征：不恰当的结果会对现实影响很大</strong>）等领域，我们必须搞清楚深度学习是怎样起作用的，什么时候深度学习不起作用，为什么会这样？</p>
<p>作者举出了一些深度学习不起作用的例子，比如图像识别识别一头羊，但是神经网络却学会用背景识别羊而非羊本身的特征（羊一般都和草一起出现），识别茶壶的时候看到茶壶花纹出现就认为是茶壶，看到肺炎医院的token出现就把这张图片识别为有肺炎等等，见图1。以上这些神经网络“投机取巧”式学习使用到的特征被我们称之为Shortcut。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/Figure1.png" alt=""></p>
<h2 id="2-Shortcut-learning-in-biological-neural-networks">2. Shortcut learning in biological neural networks</h2>
<p>作者在第二节中以小鼠走迷宫(discriminated the colours by the odour of the colour paint used on the walls of the maze instead of  using vision systems) 、死记硬背学习法(learned the whole book chapter by rote Vs. immersing oneself in the whole history)这两个例子从生物的神经网络层面介绍了Shortcut learning。</p>
<h2 id="3-Shortcut-learning-in-Education-surface-learning">3. Shortcut learning in Education: surface learning</h2>
<p>在第三节中，作者提出了一个toy model来证明神经网络在学习时的的确确会存在shortcut learning的模式。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/Figure2.png" alt=""></p>
<p>见上图，人类识别月亮和星星是通过形状来进行的，这也是人类希望神经网络这样做，然而神经网络却根据<strong>图像出现的位置</strong>进行识别，这就是一种Shortcut Learning。作者将神经网络在训练过程中可能用到的方法进行归类：</p>
<h3 id="3-1-all-possible-decision-rules-including-non-solutions">3.1 all possible decision rules, including non-solutions</h3>
<p>这个意思是通过检测图片中是否有白色像素，如果有的话则认为是star，很明显这种solution很难达到令人满意的效果。</p>
<h3 id="3-2-training-solutions-including-overfitting-solutions">3.2 training solutions, including overfitting solutions</h3>
<p>这个意思是模型完全使用训练集中的特征(假设测试集iid)，从而使预测结果过拟合，并没有给出实际例子。</p>
<h3 id="3-3-i-i-d-test-solutions-including-shortcuts">3.3 i.i.d. test solutions, including shortcuts</h3>
<p>这个意思是我们训练的模型很完美的将训练集和i.i.d的测试集都拟合了，然而简单想想模型的拟合方式也可以有：判断形状、计算白色像素的数量、看图形出现的位置等解决办法。因为测试集中都是独立同分布的数据，我们没法验证这个问题。而后用ood(out-of-distribution)的数据集测试时我们发现模型是学会了看图形出现的位置判断是moon还是star，这就是一种shortcut。</p>
<h3 id="3-4-intended-solution">3.4 intended solution</h3>
<p>通过上面三种类型我们知道了一个好的模型需要既能在iid测试集上效果好也能解决ood数据集，这种模型学到的solution就是我们想要的(<strong>intended solution</strong>)。</p>
<p>以上几种solution可以用下图进行分类。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/Figure3.png" alt=""></p>
<h2 id="4-Shortcuts-where-do-they-come-from">4. Shortcuts: where do they come from?</h2>
<p>在第四节中，作者讨论了shortcuts的来源，分为以下几个方面：</p>
<h3 id="4-1-Dataset-shortcut-opportunities">4.1 Dataset: shortcut opportunities</h3>
<p>主要是讲<strong>Dataset Bias</strong>，即要识别的物体的背景会干扰预测，如果一头奶牛出现在水里，神经网络很难将其识别为奶牛（相比于在草地里而言）。如果仅仅将数据集放大几个量级，dataset bias的问题不可能消失。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/CowInWater.png" alt=""></p>
<h3 id="4-2-Decision-rule-shortcuts-from-discriminative-learning">4.2 Decision rule: shortcuts from discriminative learning</h3>
<p>如果把图片中猫的皮肤换成大象皮肤的纹理，神经网络很有可能会把猫识别成大象，因为神经网络识别时很依赖texture，很有可能忽略了global object shape。因而模型在做决定时最好不要仅仅依赖一种特征，不然很容易造成shortcuts，然而和人类判断一模一样也不一定是好的，比如疾病检测时人们希望机器可以表现得优于人类。判别式学习(discriminative learning)可能会导致某些决策规则依赖于单个预测像素，忽略了其他的证据；Standard DNN不会对中间图像表示加任何可解释性的要求（换句话说，学出来的representation无法解释含义，就单纯直接用了），所以会导致模型严重偏向于提取简单的特征，这样会导致模型泛化力下降。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/ElephantCat.png" alt=""></p>
<h3 id="4-3-Generalisation-how-shortcuts-can-be-revealed">4.3 Generalisation: how shortcuts can be revealed</h3>
<p>泛化与捷径学习：泛化和鲁棒性可以认为是shortcut learning的另一面，shortcut learning可能是泛化到了一个不好的层面。同时，DNN和人类对物体变化的敏感程度也不同，比如旋转、噪声于人和抽象与DNN，见图4。泛化失败并不是学习失败也不是不能泛化，而是没有在预期方向上泛化。使用特定的一组特征会导致对其他特征不敏感。只有在分布变化后所选特征仍然存在时，模型才会泛化到o.o.d数据集上。</p>
<h2 id="5-Shortcut-learning-across-deep-learning">5. Shortcut learning across deep learning</h2>
<p>作者在第五节介绍了一些深度学习中具体的领域中的Shortcut Learning。</p>
<h3 id="5-1-Computer-Vision：">5.1 Computer Vision：</h3>
<p>图像的平移、旋转、加噪声、模糊、换背景、换纹理都有可能造成DNN识别图像错误。对于CV领域的Shortcuts来说，domain transfer（跨数据集间的模型迁移）就是一个challenging problem，因为模型经常要用到domain-specfic shortcut features。此外，adversarial examples也可以认为是一种shortcut learning的结果，因为人眼不可见的改变导致DNN的预测结果变了。</p>
<h3 id="5-2-Natural-Language-Processing：">5.2 Natural Language Processing：</h3>
<p>BERT、GPT-2等模型都需要有一些cue words才能用，比如以下例子：</p>
<blockquote>
<p>It learned that within a dataset of natural language arguments, detecting the presence of “not” was sufficient to perform above chance in finding the correct line of argumentation.</p>
</blockquote>
<p>在验证正确方法时，简单的通过找“不”这个字来进行，这样完全不需要理解文章的内容就可以做到了。并且在NLP中也会有一些dataset bias比如annotation artefacts的问题（Question：这是什么问题？），此外，feature combination大多都含有比如word length等这种shortcut features。这也是导致NLP任务很难泛化的原因之一。</p>
<h3 id="5-3-Reinforcement-Learning">5.3 Reinforcement Learning</h3>
<p>tbd</p>
<h3 id="5-4-Fairness-algorithmic-decision-making">5.4 Fairness &amp; algorithmic decision-making</h3>
<blockquote>
<p>Tasked to predict strong candidates on the basis of their resumes, a hiring tool developed by Amazon was found to be biased towards preferring men. The model, trained on previous human decisions, found gender to be such a strong predictor that even removing applicant names would not help: The model always found a way around, for instance by inferring gender from all-woman college names.</p>
</blockquote>
<p>一些公平算法的设计中总会遇到类似的shortcut：当模型发现了一种决定预测的特征时，即使只是所有特征的一部分，模型也会倾向于根据这种特征进行预测。这被称之为<strong>bias amplification</strong>。还有比如因为关注数据集中的多数群体从而包容少数群体的高错误率（决定让绝大多数人满意，但是忽略了少数群体），会放大现有的社会差异，称之为<strong>disparity amplification</strong>，因为模型中的sequential feedback loops会放大模型对多数群体的依赖。</p>
<h2 id="6-Diagnosing-and-understanding-shortcut-learning">6. Diagnosing and understanding shortcut learning</h2>
<p>在本节中作者提出了三种shortcut learning的分析与解决办法。</p>
<h3 id="6-1-Interpreting-results-carefully">6.1 Interpreting results carefully</h3>
<h4 id="6-1-1-Distinguishing-datasets-and-underlying-abilities">6.1.1 Distinguishing datasets and underlying abilities</h4>
<p>机器学习中most popular benchmarks仍然是i.i.d测试集，以ImageNet为例，它衡量模型“对象识别”的能力，但DNN主要是通过计算纹理来达成这一结果的，或者对于自然语言推理任务而言，一些语言模型通过检索关键词达到投机取巧的效果。总之，只有在数据集能很好的代表人们所需要的能力时它才是合适的数据集。</p>
<h4 id="6-1-2-Morgan’s-Canon-for-machine-learning">6.1.2 Morgan’s Canon for machine learning</h4>
<p>以前文提到的小老鼠走迷宫为例，小老鼠通过闻迷宫上不同位置涂的油漆的味道来辨别方向，而不是人们所希望的通过视觉辨别方向。动物(Neural Network)通常会不使用人们实际感兴趣的潜在能力，而是通过以意想不到的方式解决实验范式(Dataset)来欺骗实验者。因而我们将心理学家Morgan所提出的一条原则应用到机器学习中：永远不要将可以通过shortcut learning充分解释的能力归功于高级能力。</p>
<h4 id="6-1-3-Testing-surprisingly-strong-baselines">6.1.3 Testing (surprisingly) strong baselines</h4>
<p>用一些比较好的baseline来测试他们是否取得超出预期的效果，即使他们没有使用预期的特征（用了一些shortcuts），比如使用KNN估计地理位置，使用局部特征进行对象识别，基于单个提示词的推理等等。</p>
<h3 id="6-2-Detecting-shortcuts-towards-o-o-d-generalisation-tests">6.2 Detecting shortcuts: towards o.o.d. generalisation tests</h3>
<h4 id="6-2-1-Making-o-o-d-generalisation-tests-a-standard-practice">6.2.1 Making o.o.d. generalisation tests a standard practice</h4>
<p>大部分都是通过i.i.d测试集来评估模型指标，我们使用o.o.d测试集来评估模型可以更好的得出预测结果。比如，在死记硬背学习法的例子中，我们把选择题换成论述题，就会很大程度减少这种问题。<strong>本质上讲就是make test set more challenging 。</strong></p>
<h4 id="6-2-2-Designing-good-o-o-d-tests">6.2.2 Designing good o.o.d. tests</h4>
<p>如何定义一个好的o.o.d test？</p>
<ol>
<li>
<p>需要有clear distribution shift，不管是否能被人类区分。</p>
</li>
<li>
<p>需要有一个明确的intended solution，所以在普通图像上训练，在白噪音图像中测试是一个o.o.d测试，但却没有intended solution。</p>
</li>
<li>
<p>一个好的o.o.d test应该是让目前主流的模型很挣扎的。</p>
</li>
</ol>
<p>o.o.d test应该是和他们想评估的模型一起发展的，作者也提供了一些encouraging examples，见Box 1。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/Box1.png" alt=""></p>
<h3 id="6-3-Shortcuts-why-are-they-learned">6.3 Shortcuts: why are they learned?</h3>
<h4 id="6-3-1-The-“Principle-of-Least-Effort”">6.3.1 The “Principle of Least Effort”</h4>
<p>在语言学中，有一种现象被称为“最少努力原则”，就是沟通者会尽量减少交流中所涉及的努力，比如用plane代替airplane等等，总之就是不要多做，够了就行。</p>
<h4 id="6-3-2-Understanding-the-influence-of-inductive-biases">6.3.2 Understanding the influence of inductive biases</h4>
<p>解决方案是否易于让机器学习不仅取决于数据，还取决于机器学习算法的四个部分：<strong>architecture, training data, loss function, and optimization.</strong> shortcut learning和inductive bias(归纳偏差)的关系可以在Box 2中看到。</p>
<p><img src="https://raw.githubusercontent.com/Apple1203/apple1203.github.io/master/medias/postaddinpics/ShortcutLearningInDeepNeuralNetworks/Box2.png" alt=""></p>
<h3 id="6-4-Beyond-shortcut-learning">6.4 Beyond shortcut learning</h3>
<p>在本节中作者提出了一些可以避免shortcut learning的办法</p>
<h4 id="6-4-1-Domain-specific-prior-knowledge">6.4.1 Domain-specific prior knowledge</h4>
<ol>
<li>
<p>通过设计不鼓励学到shortcut features的结构和数据增强策略来避免对unintended cues的依赖。</p>
</li>
<li>
<p>如果对象的方位与他的类别无关，可以使用数据增强或者hard-coded rotation invariance(简单来说应该就是旋转)</p>
</li>
<li>
<p>Extreme data-augmentation，迄今为止最成功的semi-supervised和self-supervised方法的核心成分</p>
</li>
</ol>
<h4 id="6-4-2-Adversarial-examples-and-robustness">6.4.2 Adversarial examples and robustness</h4>
<p>对产生特定输出的输入的最小更改。实现与人类意图一致的预测的反事实解释，使得对抗鲁棒性的最终目标与机器学习中的因果关系研究紧密耦合。但相关研究主要侧重于与模型无关的噪声，如图像损坏等。</p>
<h4 id="6-4-3-Domain-adaptation-generalisation-and-randomisation">6.4.3 Domain adaptation, -generalisation and -randomisation</h4>
<p>通常，在训练期间会观察到多个分布，并且模型应该在测试时推广到<strong>新的分布</strong>。在某些假设下，可以从多个领域和环境中学习intended (even casual) solution。在机器人技术中，域随机化（在训练期间随机设置某些模拟参数）是一种非常成功的学习策略的方法，可以推广到现实世界中的类似情况。（主要针对o.o.d）</p>
<h4 id="6-4-4-Fairness">6.4.4 Fairness</h4>
<p>个体公平旨在以类似方式对待相似的个体，而群体公平旨在对待与其他人群没有区别的子群体。公平与泛化和因果关系密切相关。敏感组成员身份可以被视为一个领域指标：就像机器决策通常不应该受到改变数据领域的影响一样，它们也<strong>不应该偏向少数群体</strong>。</p>
<h4 id="6-4-5-Meta-learning">6.4.5 Meta-learning</h4>
<p>学习可以快速适应新条件的表示。</p>
<h4 id="6-4-6-Generative-modelling-and-disentanglement">6.4.6 Generative modelling and disentanglement</h4>
<p>Research on disentanglement addresses this shortcoming by learning generative models with well-structured latent representations.  The goal is to recover the true generating factors of the data distribution from observations by identifying independent causal mechanisms.</p>
<h2 id="7-Conclusion">7. Conclusion</h2>
<blockquote>
<p>The road reaches every place, the short cut only one. – James Richardson</p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://apple1203.github.io">Minghao Wang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://apple1203.github.io/posts/60344.html">http://apple1203.github.io/posts/60344.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://apple1203.github.io" target="_blank">Minghao's Page</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Medical-AI/">Medical AI</a><a class="post-meta__tags" href="/tags/Paper-Sharing/">Paper Sharing</a></div><div class="post_share"><div class="social-share" data-image="/medias/PostPics/16.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/11244.html"><img class="prev-cover" src="/medias/PostPics/hkust.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">OneDrive文件移动</div></div></a></div><div class="next-post pull-right"><a href="/posts/6940.html"><img class="next-cover" src="/medias/PostPics/hkust.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">本周进度20220802</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/18395.html" title="FairPrune Achieving Fairness Through Pruning for Dermatological Disease Diagnosis"><img class="cover" src="/medias/PostPics/16.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-29</div><div class="title">FairPrune Achieving Fairness Through Pruning for Dermatological Disease Diagnosis</div></div></a></div><div><a href="/posts/59723.html" title="TENT Fully Test-time Adaptation by Entropy Minimization"><img class="cover" src="/medias/PostPics/16.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-26</div><div class="title">TENT Fully Test-time Adaptation by Entropy Minimization</div></div></a></div><div><a href="/posts/31455.html" title="Summarization for Debiasing Metrics"><img class="cover" src="/medias/PostPics/16.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-06</div><div class="title">Summarization for Debiasing Metrics</div></div></a></div><div><a href="/posts/15343.html" title="Generalizing to Unseen Domains A Survey on Domain Generalization"><img class="cover" src="/medias/PostPics/16.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-01</div><div class="title">Generalizing to Unseen Domains A Survey on Domain Generalization</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/minghao.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Minghao Wang</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/apple1203"><i class="fab fa-github"></i><span>Follow Me @ github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/apple1203" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:mwangcx@connect.ust.hk" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="GoogleScholar:https://scholar.google.com/citations?hl=zh-TW&amp;user=7MeFEVwAAAAJ" target="_blank" title="GoogleScholar"><i class="fa-solid fa-graduation-cap"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p>17/09&nbsp;One&nbsp;paper&nbsp;was&nbsp;accepted&nbsp;by&nbsp;<br>Frontiers&nbsp;in&nbsp;Public&nbsp;Health!&nbsp;(if=6.7)<br>26/07&nbsp;Joined&nbsp;Smart&nbsp;Lab@HKUST</p></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Shortcut Learning – 捷径学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-number">1.1.</span> <span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Shortcut-learning-in-biological-neural-networks"><span class="toc-number">1.2.</span> <span class="toc-text">2. Shortcut learning in biological neural networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Shortcut-learning-in-Education-surface-learning"><span class="toc-number">1.3.</span> <span class="toc-text">3. Shortcut learning in Education: surface learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-all-possible-decision-rules-including-non-solutions"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 all possible decision rules, including non-solutions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-training-solutions-including-overfitting-solutions"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 training solutions, including overfitting solutions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-i-i-d-test-solutions-including-shortcuts"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 i.i.d. test solutions, including shortcuts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-intended-solution"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 intended solution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Shortcuts-where-do-they-come-from"><span class="toc-number">1.4.</span> <span class="toc-text">4. Shortcuts: where do they come from?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Dataset-shortcut-opportunities"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 Dataset: shortcut opportunities</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Decision-rule-shortcuts-from-discriminative-learning"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 Decision rule: shortcuts from discriminative learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Generalisation-how-shortcuts-can-be-revealed"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 Generalisation: how shortcuts can be revealed</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Shortcut-learning-across-deep-learning"><span class="toc-number">1.5.</span> <span class="toc-text">5. Shortcut learning across deep learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Computer-Vision%EF%BC%9A"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 Computer Vision：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Natural-Language-Processing%EF%BC%9A"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 Natural Language Processing：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Reinforcement-Learning"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 Reinforcement Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-Fairness-algorithmic-decision-making"><span class="toc-number">1.5.4.</span> <span class="toc-text">5.4 Fairness &amp; algorithmic decision-making</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Diagnosing-and-understanding-shortcut-learning"><span class="toc-number">1.6.</span> <span class="toc-text">6. Diagnosing and understanding shortcut learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-Interpreting-results-carefully"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 Interpreting results carefully</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-1-Distinguishing-datasets-and-underlying-abilities"><span class="toc-number">1.6.1.1.</span> <span class="toc-text">6.1.1 Distinguishing datasets and underlying abilities</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-2-Morgan%E2%80%99s-Canon-for-machine-learning"><span class="toc-number">1.6.1.2.</span> <span class="toc-text">6.1.2 Morgan’s Canon for machine learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-3-Testing-surprisingly-strong-baselines"><span class="toc-number">1.6.1.3.</span> <span class="toc-text">6.1.3 Testing (surprisingly) strong baselines</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-Detecting-shortcuts-towards-o-o-d-generalisation-tests"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 Detecting shortcuts: towards o.o.d. generalisation tests</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2-1-Making-o-o-d-generalisation-tests-a-standard-practice"><span class="toc-number">1.6.2.1.</span> <span class="toc-text">6.2.1 Making o.o.d. generalisation tests a standard practice</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2-2-Designing-good-o-o-d-tests"><span class="toc-number">1.6.2.2.</span> <span class="toc-text">6.2.2 Designing good o.o.d. tests</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-Shortcuts-why-are-they-learned"><span class="toc-number">1.6.3.</span> <span class="toc-text">6.3 Shortcuts: why are they learned?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-1-The-%E2%80%9CPrinciple-of-Least-Effort%E2%80%9D"><span class="toc-number">1.6.3.1.</span> <span class="toc-text">6.3.1 The “Principle of Least Effort”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-2-Understanding-the-influence-of-inductive-biases"><span class="toc-number">1.6.3.2.</span> <span class="toc-text">6.3.2 Understanding the influence of inductive biases</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-Beyond-shortcut-learning"><span class="toc-number">1.6.4.</span> <span class="toc-text">6.4 Beyond shortcut learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-1-Domain-specific-prior-knowledge"><span class="toc-number">1.6.4.1.</span> <span class="toc-text">6.4.1 Domain-specific prior knowledge</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-2-Adversarial-examples-and-robustness"><span class="toc-number">1.6.4.2.</span> <span class="toc-text">6.4.2 Adversarial examples and robustness</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-3-Domain-adaptation-generalisation-and-randomisation"><span class="toc-number">1.6.4.3.</span> <span class="toc-text">6.4.3 Domain adaptation, -generalisation and -randomisation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-4-Fairness"><span class="toc-number">1.6.4.4.</span> <span class="toc-text">6.4.4 Fairness</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-5-Meta-learning"><span class="toc-number">1.6.4.5.</span> <span class="toc-text">6.4.5 Meta-learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-6-Generative-modelling-and-disentanglement"><span class="toc-number">1.6.4.6.</span> <span class="toc-text">6.4.6 Generative modelling and disentanglement</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Conclusion"><span class="toc-number">1.7.</span> <span class="toc-text">7. Conclusion</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By Minghao Wang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://apple1203.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>